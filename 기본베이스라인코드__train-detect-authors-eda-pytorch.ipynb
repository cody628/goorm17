{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"},{"sourceId":6868189,"sourceType":"datasetVersion","datasetId":3937441}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <p style=\"background-color:#C1FFC1;font-family:cursive;color:#A0522D;font-size:150%;text-align:center;border-radius:10px 10px;line-height:1.5\">LLM - Detect AI Generated Text</p>","metadata":{}},{"cell_type":"markdown","source":"<h1 align='center'>Introduction üìù</h1>\nWelcome to a competition where we need to determine whether an essay was authored by a student or an LLM. Within this notebook, my initial focus will involve delving into the dataset. I'll employ the magic of plotly for a comprehensive exploration of the data, followed by subsequent stages of data processing and modeling.","metadata":{}},{"cell_type":"markdown","source":"<h1 align='center'>Dataset Info üìà</h1>\n<h2>Training Data</h2>\n<b>{test|train}_essays.csv</b><br>\n\n* ```id``` - A unique identifier for each essay.\n* ```prompt_id``` - Identifies the prompt the essay was written in response to.\n* ```text``` - The essay text itself.\n* ```generated``` - Whether the essay was written by a student (0) or generated by an LLM (1). This field is the target and is not present in test_essays.csv.\n\n<b>train_prompts.csv - Essays were written in response to information in these fields.</b><br>\n\n* ```prompt_id``` - A unique identifier for each prompt.\n* ```prompt_name``` - The title of the prompt.\n* ```instructions``` - The instructions given to students.\n* ```source_text``` - The text of the article(s) the essays were written in response to, in Markdown format.","metadata":{}},{"cell_type":"markdown","source":"<h1 align='center'>Evaluation Metric üìê</h1>\nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"background-color:#C1FFC1;font-family:cursive;color:#A0522D;font-size:150%;text-align:center;border-radius:10px 10px;line-height:1.5\">TABLE OF CONTENTS</p>\n<ul style=\"list-style-type:square\">\n    <li><a href=\"#1\">Importing Libraries</a></li>\n    <li><a href=\"#2\">Reading the data</a></li>\n    <li><a href=\"#3\">Exploratory Data Analysis</a></li>\n    <li><a href=\"#4\">Create Folds</a></li>\n    <li><a href=\"#5\">Dataset Class</a></li>\n    <li><a href=\"#6\">Baseline Model</a></li>\n    <li><a href=\"#7\">Utility Functions</a></li>\n</ul>","metadata":{}},{"cell_type":"markdown","source":"<a id='1'></a>\n\n# <p style=\"background-color:#C1FFC1;font-family:cursive;color:#A0522D;font-size:150%;text-align:center;border-radius:10px 10px;line-height:1.5\">IMPORTING LIBRARIES</p>","metadata":{}},{"cell_type":"code","source":"import gc\nimport os\nimport wandb\nimport random\nimport requests\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nfrom PIL import Image\nimport plotly.io as pio\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS\nfrom kaggle_secrets import UserSecretsClient\n\nimport torch\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom torch.optim import AdamW\nfrom sklearn.metrics import roc_auc_score\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import StratifiedKFold\nfrom transformers import AutoTokenizer, AutoConfig, AutoModel, get_linear_schedule_with_warmup\n\nimport warnings\nwarnings.simplefilter('ignore')\n\n# Set global template and layout colors\npio.templates.default = \"plotly_dark\"\npio.templates[pio.templates.default].layout['paper_bgcolor'] = '#1F1F1F'\npio.templates[pio.templates.default].layout['plot_bgcolor'] = '#1F1F1F'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-24T18:36:02.830956Z","iopub.execute_input":"2023-12-24T18:36:02.831956Z","iopub.status.idle":"2023-12-24T18:36:02.862089Z","shell.execute_reply.started":"2023-12-24T18:36:02.83192Z","shell.execute_reply":"2023-12-24T18:36:02.861056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CONFIG:\n    seed=300\n    num_fold = 3\n    model = 'roberta-base'\n    max_len = 512\n    train_batch_size = 16\n    valid_batch_size = 16\n    epochs = 2\n    learning_rate = 1e-5\n    scheduler = 'linear'\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    tokenizer = AutoTokenizer.from_pretrained(model)\n    \nCONFIG.tokenizer.save_pretrained('./tokenizer/')","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:03.001833Z","iopub.execute_input":"2023-12-24T18:36:03.002126Z","iopub.status.idle":"2023-12-24T18:36:03.460009Z","shell.execute_reply.started":"2023-12-24T18:36:03.0021Z","shell.execute_reply":"2023-12-24T18:36:03.458997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nseed_everything(CONFIG.seed)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:03.462034Z","iopub.execute_input":"2023-12-24T18:36:03.462496Z","iopub.status.idle":"2023-12-24T18:36:03.470319Z","shell.execute_reply.started":"2023-12-24T18:36:03.462457Z","shell.execute_reply":"2023-12-24T18:36:03.469391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<img src = \"https://awsmp-logos.s3.amazonaws.com/3426ff8f-c4da-4d6d-ae6c-46a02b4b0dc4/afbc6b177af177c2243749dfa88e0dec.png\" style =\"height:65%;width:65%;\">\n\n### I'll be utilizing W&B to monitor the model's performance.\n\nhttps://github.com/ultralytics/yolov5/issues/2362","metadata":{}},{"cell_type":"code","source":"# Weights & Biases (optional)\n%pip install -q wandb ","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:31:14.408562Z","iopub.execute_input":"2023-12-24T18:31:14.408844Z","iopub.status.idle":"2023-12-24T18:31:28.202135Z","shell.execute_reply.started":"2023-12-24T18:31:14.40882Z","shell.execute_reply":"2023-12-24T18:31:28.200928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:31:28.203577Z","iopub.execute_input":"2023-12-24T18:31:28.203883Z","iopub.status.idle":"2023-12-24T18:31:37.611182Z","shell.execute_reply.started":"2023-12-24T18:31:28.203857Z","shell.execute_reply":"2023-12-24T18:31:37.61027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='2'></a>\n\n# <p style=\"background-color:#C1FFC1;font-family:cursive;color:#A0522D;font-size:150%;text-align:center;border-radius:10px 10px;line-height:1.5\">READING THE DATA</p>","metadata":{}},{"cell_type":"code","source":"df_ess = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\")\ndf_ess.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:05.732913Z","iopub.execute_input":"2023-12-24T18:36:05.733308Z","iopub.status.idle":"2023-12-24T18:36:05.883423Z","shell.execute_reply.started":"2023-12-24T18:36:05.733278Z","shell.execute_reply":"2023-12-24T18:36:05.882461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_ess.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:05.976778Z","iopub.execute_input":"2023-12-24T18:36:05.977076Z","iopub.status.idle":"2023-12-24T18:36:06.015407Z","shell.execute_reply.started":"2023-12-24T18:36:05.977051Z","shell.execute_reply":"2023-12-24T18:36:06.014533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pro = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\")\ndf_pro.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:06.10747Z","iopub.execute_input":"2023-12-24T18:36:06.107756Z","iopub.status.idle":"2023-12-24T18:36:06.123028Z","shell.execute_reply.started":"2023-12-24T18:36:06.107733Z","shell.execute_reply":"2023-12-24T18:36:06.122178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pro.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:06.309612Z","iopub.execute_input":"2023-12-24T18:36:06.309868Z","iopub.status.idle":"2023-12-24T18:36:06.319544Z","shell.execute_reply.started":"2023-12-24T18:36:06.309847Z","shell.execute_reply":"2023-12-24T18:36:06.31857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thanks to @radek1 . Please upvote his dataset also - [LLM Generated Essays for the Detect AI Comp!](https://www.kaggle.com/datasets/radek1/llm-generated-essays)","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n# External bir dataset olu≈üturulmu≈ü, bu import'lanƒ±yor.","metadata":{}},{"cell_type":"code","source":"## External Dataset\ndf_gpt_3_5 = pd.read_csv(\"/kaggle/input/llm-generated-essays/ai_generated_train_essays.csv\")\ndf_gpt_4 = pd.read_csv(\"/kaggle/input/llm-generated-essays/ai_generated_train_essays_gpt-4.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:07.298697Z","iopub.execute_input":"2023-12-24T18:36:07.299052Z","iopub.status.idle":"2023-12-24T18:36:07.384893Z","shell.execute_reply.started":"2023-12-24T18:36:07.299024Z","shell.execute_reply":"2023-12-24T18:36:07.384109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_gpt_3_5.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:07.569549Z","iopub.execute_input":"2023-12-24T18:36:07.569849Z","iopub.status.idle":"2023-12-24T18:36:07.58008Z","shell.execute_reply.started":"2023-12-24T18:36:07.569824Z","shell.execute_reply":"2023-12-24T18:36:07.579284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_gpt_4.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:08.075041Z","iopub.execute_input":"2023-12-24T18:36:08.075392Z","iopub.status.idle":"2023-12-24T18:36:08.085635Z","shell.execute_reply.started":"2023-12-24T18:36:08.075364Z","shell.execute_reply":"2023-12-24T18:36:08.084671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n### Olu≈üturulan external veri setiyle orijinal veri seti birle≈ütirilir.","metadata":{}},{"cell_type":"code","source":"## Combining the original and external dataset\ndf_new = pd.concat([df_ess, df_gpt_3_5, df_gpt_4]).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:08.666567Z","iopub.execute_input":"2023-12-24T18:36:08.667244Z","iopub.status.idle":"2023-12-24T18:36:08.679868Z","shell.execute_reply.started":"2023-12-24T18:36:08.667201Z","shell.execute_reply":"2023-12-24T18:36:08.678847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='3'></a>\n\n# <p style=\"background-color:#C1FFC1;font-family:cursive;color:#A0522D;font-size:150%;text-align:center;border-radius:10px 10px;line-height:1.5\">EXPLORATORY DATA ANALYSIS</p>","metadata":{}},{"cell_type":"markdown","source":"### To begin, we'll initiate the exploration process exclusively on the **original dataset**.<br>\n## Distribution of Target Variable - Generated","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n   \n    \n### Generated deƒüi≈ükenine bakarak veri sayƒ±sƒ±nƒ± g√∂rselle≈ütiriyoruz.","metadata":{}},{"cell_type":"code","source":"# Create a temporary dataframe with counts of each category\ncount_df = df_ess['generated'].value_counts().reset_index()\ncount_df.columns = ['generated', 'count']\n\nfig = px.bar(\n    count_df,\n    x='generated',\n    y='count',\n    title='Distribution of Generated Label',\n    color=['#2E86AB', '#E84545'],\n    color_discrete_map=\"identity\"\n)\n\n# Customize layout for value display\nfig.update_layout(\n    xaxis=dict(\n        tickmode='array',\n        tickvals=[0, 1])\n)\n\n# Display values on top of the bars\nfig.update_traces(\n    texttemplate='%{y}',  \n    textposition='outside', \n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:09.853176Z","iopub.execute_input":"2023-12-24T18:36:09.853616Z","iopub.status.idle":"2023-12-24T18:36:10.302223Z","shell.execute_reply.started":"2023-12-24T18:36:09.853583Z","shell.execute_reply":"2023-12-24T18:36:10.301265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### INSIGHTS\n\n* The graph clearly shows that the dataset is highly imbalanced, with class 0 being the majority class.\n* There are a number of techniques that can be used to address class imbalance, such as upsampling and downsampling.\n* In this case, we will do upsampling and this is the reason we are using external dataset.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n### Bulgular:\nVeri seti dengesiz, √∂ƒürenciler tarafƒ±ndan olu≈üturulmu≈ü makale sayƒ±sƒ± √ºst√ºnl√ºkte.\nBu dengesizliƒüi d√ºzeltebilmek i√ßin upsampling ve downsampling gibi teknikler kullanƒ±labilir. Bu Notebook'ta upsampling kullanƒ±lacak, bu y√ºzden external dataset'ini importladƒ±k.","metadata":{}},{"cell_type":"markdown","source":"## Exploration of Essay Text","metadata":{}},{"cell_type":"code","source":"df_ess['essay_len'] = df_ess['text'].str.split().map(lambda x : len(x))\n\nfig = px.histogram(\n    df_ess,\n    x='essay_len',\n    title='Distribution of word count of text',\n    color_discrete_sequence=['#FF7F0E'], \n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:11.366Z","iopub.execute_input":"2023-12-24T18:36:11.366866Z","iopub.status.idle":"2023-12-24T18:36:11.558726Z","shell.execute_reply.started":"2023-12-24T18:36:11.366834Z","shell.execute_reply":"2023-12-24T18:36:11.557852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### INSIGHTS\n\n* The histogram shows that mostly essay has around 500-600 words.\n* It also displays some outliers, with a few essays exceeding 1200 words.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n    \n# Bulgular\n√áoƒüu makale 500-600 kelimeye sahip. Birka√ß tane aykƒ±rƒ± deƒüer bulunuyor (1200 kelimelik makaleler)","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(\n    df_ess,\n    x='essay_len',\n    title='Word Count Distribution Across Prompts',\n    color=\"prompt_id\",\n    color_discrete_sequence=px.colors.qualitative.Bold,\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:12.73616Z","iopub.execute_input":"2023-12-24T18:36:12.736546Z","iopub.status.idle":"2023-12-24T18:36:12.816107Z","shell.execute_reply.started":"2023-12-24T18:36:12.736516Z","shell.execute_reply":"2023-12-24T18:36:12.815215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## INSIGHTS\n* This shows that the essays proposed by prompt id 0 are generally longer than the essays proposed by prompt id 1.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n   \n   \n    \n# Bulgular\n0.prompt_id'ye kar≈üƒ±lƒ±k olarak yazƒ±lmƒ±≈ü makaleler genel olarak, 1. prompt id'ye kar≈üƒ±lƒ±k olarak yazƒ±lmƒ±≈ü makalelerden daha uzun.","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:35:14.032513Z","iopub.execute_input":"2023-12-24T18:35:14.032924Z","iopub.status.idle":"2023-12-24T18:35:14.040482Z","shell.execute_reply.started":"2023-12-24T18:35:14.032893Z","shell.execute_reply":"2023-12-24T18:35:14.039226Z"}}},{"cell_type":"markdown","source":"### After conducting preliminary exploration, we will now delve into our **updated dataset**, which incorporates an **external dataset**. This adjustment is necessary since the original dataset is highly biased, making it unsuitable for effective model generation.","metadata":{}},{"cell_type":"markdown","source":"## Distribution of Target Variable - Generated","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n    \n    \n    \n#### Kodun devamƒ±nda, external dataset dahil edilmi≈ü olan g√ºncel veri seti kullanƒ±lacak. Bu ≈üekilde daha dengeli bir veri seti olacak.","metadata":{}},{"cell_type":"code","source":"# Create a temporary dataframe with counts of each category\ncount_df = df_new['generated'].value_counts().reset_index()\ncount_df.columns = ['generated', 'count']\n\nfig = px.bar(\n    count_df,\n    x='generated',\n    y='count',\n    title='Distribution of Generated Label',\n    color=['#FECB52', '#FF97FF'],\n    color_discrete_map=\"identity\"\n)\n\n# Customize layout for value display\nfig.update_layout(\n    xaxis=dict(\n        tickmode='array',\n        tickvals=[0, 1])\n)\n\n# Display values on top of the bars\nfig.update_traces(\n    texttemplate='%{y}',  \n    textposition='outside', \n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:14.579869Z","iopub.execute_input":"2023-12-24T18:36:14.580599Z","iopub.status.idle":"2023-12-24T18:36:14.656698Z","shell.execute_reply.started":"2023-12-24T18:36:14.580564Z","shell.execute_reply":"2023-12-24T18:36:14.655713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## INSIGHTS\n* The dataset is now have been more balanced by upsampling the data.","metadata":{}},{"cell_type":"markdown","source":"## Distribution of Prompt ID","metadata":{}},{"cell_type":"code","source":"fig_hist = px.histogram(\n    df_new,\n    x='prompt_id',\n    title='Prompt ID Distribution by Generated Category',\n    color='generated',\n    barmode='group',\n    color_discrete_sequence=px.colors.qualitative.D3[3:],\n)\n\n# Display values on top of the bars\nfig_hist.update_traces(\n    texttemplate='%{y}',  \n    textposition='outside',  \n)\n\nfig_hist.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:37:22.556759Z","iopub.execute_input":"2023-12-24T18:37:22.557444Z","iopub.status.idle":"2023-12-24T18:37:22.636638Z","shell.execute_reply.started":"2023-12-24T18:37:22.557413Z","shell.execute_reply":"2023-12-24T18:37:22.63555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## INSIGHTS\n* The graph shows that the distribution of the both the prompts is almost similar.\n* We have more essays written by student for both the prompts which is expected also.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n## Prompt'lar hemen hemen e≈üit daƒüƒ±tƒ±lmƒ±≈ü. ","metadata":{}},{"cell_type":"markdown","source":"## Exploration of Essay Text","metadata":{}},{"cell_type":"code","source":"df_new['essay_len'] = df_new['text'].str.split().map(lambda x : len(x))\ndf_llm = df_new[df_new[\"generated\"]==1]\n\nfig = px.histogram(\n    df_llm,\n    x='essay_len',\n    title='Distribution of word count of text generated by LLM',\n    color_discrete_sequence=['#73AF48']\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:38:11.062019Z","iopub.execute_input":"2023-12-24T18:38:11.062838Z","iopub.status.idle":"2023-12-24T18:38:11.252724Z","shell.execute_reply.started":"2023-12-24T18:38:11.062804Z","shell.execute_reply":"2023-12-24T18:38:11.251726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### INSIGHTS\n\n* The distribution is not perfectly normal, as there is a slight skew to the right. This means that there are more essays with a higher number of words than essays with a lower number of words.\n* The majority of essays have a word count between 400-600 words.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n## Daƒüƒ±lma standard bir daƒüƒ±lƒ±m deƒüil, saƒüa doƒüru biraz kayma var. Genelde makaleler 400-600 kelime aralƒ±ƒüƒ±nda.","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(\n    df_new,\n    x='essay_len',\n    title='Distribution of word count of text grouped by prompt_id ',\n    color=\"prompt_id\",\n    color_discrete_sequence=px.colors.qualitative.Safe,\n    barmode=\"group\",\n)\n\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:39:03.790364Z","iopub.execute_input":"2023-12-24T18:39:03.790735Z","iopub.status.idle":"2023-12-24T18:39:03.856419Z","shell.execute_reply.started":"2023-12-24T18:39:03.790704Z","shell.execute_reply":"2023-12-24T18:39:03.855572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## INSIGHTS\n* The distribution of word count for prompt id 0 is more skewed to the right than the distribution of word count for prompt id 1. This suggests that there are more essays generated by prompt id 0 with a very high number of words.\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n    \n### Prompt_id 0'a kar≈üƒ±lƒ±k yazƒ±lmƒ±≈ü makalelerin kaymasƒ± daha saƒüa doƒüru fakat prompt_id 1'e kar≈üƒ±lƒ±k yazƒ±lmƒ±≈ü makalelerin kaymasƒ± daha sola doƒüru. Bu demek oluyor ki, prompt_id 0'a kar≈üƒ±lƒ±k yazƒ±lmƒ±≈ü makaleler daha fazla kelime i√ßeriyor.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n    \n# A≈üaƒüƒ±daki kodda en sƒ±k kullanƒ±lmƒ±≈ü kelimeler, sƒ±rayla √∂ƒürenciler ve LLM tarafƒ±ndan yazƒ±lmƒ±≈ü makalelere g√∂re d√ºzenlenmi≈ü.\n    \nƒ∞lk ba≈üta stopwords dahil edilmi≈ü sƒ±ralamaya (the, on, off vb. kelimeler). Sonrasƒ±nda dahil edilmeden tekrar hesaplanmƒ±≈ü.","metadata":{}},{"cell_type":"code","source":"word_occ = Counter([word.lower() for words in df_ess['text'] for word in words.split()])\ndf_temp = pd.DataFrame(word_occ.most_common(10))\ndf_temp.columns = ['Common Words','count']\n\nfig = px.bar(df_temp, \n             x='count', \n             y='Common Words', \n             title='Most Common Words (including stopwords) in Essays Written by Students', \n             orientation='h', \n             width=900,\n             height=700, \n             color='Common Words',\n            color_discrete_sequence=px.colors.qualitative.Vivid)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:40:19.360737Z","iopub.execute_input":"2023-12-24T18:40:19.361162Z","iopub.status.idle":"2023-12-24T18:40:19.716165Z","shell.execute_reply.started":"2023-12-24T18:40:19.361131Z","shell.execute_reply":"2023-12-24T18:40:19.715206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_occ = Counter([word.lower() for words in df_ess['text'] for word in words.split() if word.lower() not in set(stopwords.words(\"english\"))])\ndf_temp = pd.DataFrame(word_occ.most_common(10))\ndf_temp.columns = ['Common Words','count']\n\nfig = px.bar(df_temp, \n             x='count', \n             y='Common Words', \n             title='Most Common Words (excluding stopwords) in Essays Written by Students', \n             orientation='h', \n             width=900,\n             height=700, \n             color='Common Words',\n            color_discrete_sequence=px.colors.qualitative.Vivid)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:40:24.165385Z","iopub.execute_input":"2023-12-24T18:40:24.165757Z","iopub.status.idle":"2023-12-24T18:41:59.902708Z","shell.execute_reply.started":"2023-12-24T18:40:24.165728Z","shell.execute_reply":"2023-12-24T18:41:59.901782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_occ = Counter([word.lower() for words in df_llm['text'] for word in words.split()])\ndf_temp = pd.DataFrame(word_occ.most_common(10))\ndf_temp.columns = ['Common Words','count']\n\nfig = px.bar(df_temp, \n             x='count', \n             y='Common Words', \n             title='Most Common Words (including stopwords) in Essays Generated by LLMs', \n             orientation='h', \n             width=900,\n             height=700, \n             color='Common Words',\n            color_discrete_sequence=px.colors.qualitative.Set1)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:43:23.077109Z","iopub.execute_input":"2023-12-24T18:43:23.078015Z","iopub.status.idle":"2023-12-24T18:43:23.298897Z","shell.execute_reply.started":"2023-12-24T18:43:23.07798Z","shell.execute_reply":"2023-12-24T18:43:23.297934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_occ = Counter([word.lower() for words in df_llm['text'] for word in words.split() if word.lower() not in set(stopwords.words(\"english\"))])\ndf_temp = pd.DataFrame(word_occ.most_common(10))\ndf_temp.columns = ['Common Words','count']\n\nfig = px.bar(df_temp, \n             x='count', \n             y='Common Words', \n             title='Most Common Words (excluding stopwords) in Essays Generated by LLMs', \n             orientation='h', \n             width=900,\n             height=700, \n             color='Common Words',\n            color_discrete_sequence=px.colors.qualitative.Set1)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:43:23.343209Z","iopub.execute_input":"2023-12-24T18:43:23.34353Z","iopub.status.idle":"2023-12-24T18:44:08.959035Z","shell.execute_reply.started":"2023-12-24T18:43:23.343506Z","shell.execute_reply":"2023-12-24T18:44:08.95808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## INSIGHTS\n* The above plots reveal differences in common words between essays written by students and those generated by LLMs. \n* This observation implies that such differences could be valuable for classifying essays.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n### Sƒ±k kullanƒ±lan kelimeler arasƒ±nda LLM veya √∂ƒürenci tarafƒ±ndan yazƒ±lmƒ±≈ü olmasƒ±nƒ±n verdiƒüi bir fark var. Bu, sƒ±nƒ±flandƒ±rma i≈üleminde kullanƒ±labilir.","metadata":{}},{"cell_type":"markdown","source":"## WordCloud","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n### Kelime bulutu olu≈üturulur. En sƒ±k kullanƒ±lan kelimelerin, toplu bir ≈üekilde g√∂rselle≈ütirilmesini saƒülar.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\n\ntext = df_new['text'].values\nurl = 'https://www.llmsolicitors.co.uk/wp-content/themes/llmsolicitors/image/avatar.png'\nimg = np.array(Image.open(requests.get(url, stream=True).raw))\n\n# Center cropping\nwidth, height = img.shape[1], img.shape[0]\nmid_x, mid_y = int(width/2), int(height/2)\ncw2, ch2 = int(width/4), int(height/4) \ncrop_img = img[mid_y-ch2:mid_y+ch2, mid_x-cw2:mid_x+cw2]\n\ncloud = WordCloud(stopwords = STOPWORDS,\n                  background_color='white',\n                  min_font_size=3,\n                  mask = crop_img,\n                  max_words = 500,\n                  colormap='Dark2'\n                  ).generate(\" \".join(text))\n\nplt.imshow(cloud)\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:44:12.018366Z","iopub.execute_input":"2023-12-24T18:44:12.018728Z","iopub.status.idle":"2023-12-24T18:44:17.41087Z","shell.execute_reply.started":"2023-12-24T18:44:12.018701Z","shell.execute_reply":"2023-12-24T18:44:17.40987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4'></a>\n\n# <p style=\"background-color:#C1FFC1;font-family:cursive;color:#A0522D;font-size:150%;text-align:center;border-radius:10px 10px;line-height:1.5\">CREATE FOLDS</p>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n# Veri setini, √ßapraz doƒürulama yapma amacƒ±yla b√∂lmek i√ßin stratified k-fold i≈ülemi uygulanƒ±yor. Stratified K-Fold, her katlamada hedef deƒüi≈ükenin sƒ±nƒ±f daƒüƒ±lƒ±mƒ±nƒ±n orijinal veri seti ile aynƒ± olmasƒ±nƒ± saƒülar. Bu, √∂zellikle sƒ±nƒ±f dengesizliƒüinin olduƒüu durumlarda √∂nemlidir. Overfitting'i √∂nlemek i√ßin yapƒ±lƒ±r.","metadata":{}},{"cell_type":"code","source":"# Use Stratified K-Fold for cross-validation\nskf = StratifiedKFold(n_splits=CONFIG.num_fold, shuffle=True, random_state=CONFIG.seed)\n\n# Assign folds to the dataframe\nfor k, (_, val_ind) in enumerate(skf.split(X=df_new, y=df_new['generated'])):\n    df_new.loc[val_ind, 'fold'] = k","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:45:03.805525Z","iopub.execute_input":"2023-12-24T18:45:03.805919Z","iopub.status.idle":"2023-12-24T18:45:03.820207Z","shell.execute_reply.started":"2023-12-24T18:45:03.805886Z","shell.execute_reply":"2023-12-24T18:45:03.819302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='5'></a>\n\n# <p style=\"background-color:#C1FFC1;font-family:cursive;color:#A0522D;font-size:150%;text-align:center;border-radius:10px 10px;line-height:1.5\">DATASET CLASS</p>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n\n## LLMTextData denilen √∂zel bir sƒ±nƒ±f olu≈üturulur. \n#### \\_ \\_len_ \\_(self): Veri setindeki √∂rnek sayƒ±sƒ±nƒ± d√∂nd√ºr√ºr.\n#### \\_ \\_getitem_ \\_: Verilen bir index i√ßin veri setinden bir √∂rnek (makale ve prompt) alƒ±r.","metadata":{}},{"cell_type":"code","source":"class LLMTextData(Dataset):\n    def __init__(self, df):\n        self.text = df['text']\n        self.generated = df['generated']\n        \n    def __len__(self):\n        return len(self.text)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        generated = self.generated[index]\n        \n        inputs = CONFIG.tokenizer(text, padding='max_length', max_length=CONFIG.max_len, truncation=True)\n        \n        input_ids = inputs[\"input_ids\"]\n        attention_mask = inputs[\"attention_mask\"]\n        \n        return {\n            \"ids\": torch.tensor(input_ids, dtype=torch.long),\n            \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n            \"label\": torch.tensor(generated, dtype=torch.int),\n        }","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:51:23.296014Z","iopub.execute_input":"2023-12-24T18:51:23.296777Z","iopub.status.idle":"2023-12-24T18:51:23.304517Z","shell.execute_reply.started":"2023-12-24T18:51:23.296742Z","shell.execute_reply":"2023-12-24T18:51:23.303564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='6'></a>\n\n# <p style=\"background-color:#C1FFC1;font-family:cursive;color:#A0522D;font-size:150%;text-align:center;border-radius:10px 10px;line-height:1.5\">BASELINE MODEL</p>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n#### A≈üaƒüƒ±daki kod, makine √∂ƒürenme model sƒ±nƒ±fƒ± olu≈üturur. Metin verileri √ºzerinde √ßalƒ±≈ümak i√ßin tasarlanmƒ±≈ütƒ±r ve RoBERTa modelini kullanƒ±r (bir transformers modelidir).\n## LLMDetectModel Sƒ±nƒ±fƒ±\n\n## 1. _ \\_init_ \\_\n\nKullanƒ±lacak modelin adƒ±, modelin path'ini ve pretrained olup olmadƒ±ƒüƒ± bilgilerini alƒ±r. Eƒüer pretrained deƒüilse, config deƒüerlerinden konfig√ºrasyonu alarak modeli eƒüitir.\n \n## 2. _ \\_forward_ \\_ \nModelin nasƒ±l tahminler yapacaƒüƒ±nƒ± tanƒ±mlar. Veriler √∂nce RoBERTa modeline yollanƒ±r, ardƒ±ndan CNN teknikleri kullanƒ±larak sonu√ß elde edilir.\n    \n    \nSƒ±nƒ±f, RoBERTa sinir aƒüƒ±nƒ±  kullanarak metin verileri √ºzerinde tahminler yapmak i√ßin tasarlanmƒ±≈ütƒ±r. Sƒ±nƒ±f, modelin yapƒ±landƒ±rmasƒ±nƒ± y√ºklemek, gerektiƒüinde √∂nceden eƒüitilmi≈ü aƒüƒ±rlƒ±klarƒ± kullanmak ve ek katmanlar eklemek i√ßin kullanƒ±lƒ±r.\n    ","metadata":{}},{"cell_type":"code","source":"class LLMDetectModel(nn.Module):\n    def __init__(self, model_name, model_path=None, pretrained=True):\n        super(LLMDetectModel, self).__init__()\n        \n        if model_path is None:\n            self.config = AutoConfig.from_pretrained(model_name)\n            self.config.update({\"output_hidden_states\":True, \n                           \"hidden_dropout_prob\": 0.0,\n                           \"layer_norm_eps\": 1e-7})\n        else:\n            self.config = torch.load(model_path+\"/config.pth\")\n        \n        if pretrained:\n            self.roberta = AutoModel.from_pretrained(model_name, config=self.config)\n        else:\n            self.roberta = AutoModel.from_config(self.config)\n            \n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.linear = nn.Linear(self.config.hidden_size,1)\n        \n    def forward(self, input_ids, attention_mask=None):\n        x = self.roberta(input_ids, attention_mask)[0]\n        x = self.pool(x.permute(0, 2, 1)).view(x.size(0), -1)\n        x = self.linear(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-12-04T11:49:25.751989Z","iopub.execute_input":"2023-12-04T11:49:25.752342Z","iopub.status.idle":"2023-12-04T11:49:25.761972Z","shell.execute_reply.started":"2023-12-04T11:49:25.752309Z","shell.execute_reply":"2023-12-04T11:49:25.761119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='7'></a>\n\n# <p style=\"background-color:#C1FFC1;font-family:cursive;color:#A0522D;font-size:150%;text-align:center;border-radius:10px 10px;line-height:1.5\">UTILITY FUNCTIONS</p>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n\n### Veri Y√ºkleyicileri (Data Loaders)\n    \n#### 1. get_data(fold): \n#### Train ve validation data loader'larƒ±nƒ± al\n<hr>\n\n#### 2. loss_fn \n#### Modelin √ßƒ±ktƒ±larƒ± ile ger√ßek etiketler arasƒ±ndaki uyumsuzluƒüu hesaplar.\n<hr>\n\n#### 3. calculate_roc_auc \n#### ROC-AUC skoru hesaplar\n<hr>\n\n#### 4. get_optimizer\n#### Model parametrelerini optimize etmek i√ßin kullanƒ±lan y√∂ntemdir. Bu kodda AdamW optimizasyon algoritmasƒ± kullanƒ±lƒ±yor.\n<hr>\n\n#### 5. get_scheduler\n#### lineer veya kosin√ºs zamanlamasƒ±: √ñƒürenme oranƒ±nƒ± belirli bir stratejiye g√∂re azaltƒ±r. Modelin eƒüitim s√ºrecinde daha hƒ±zlƒ± ilerlemesini ve son a≈üamada daha hassas ayar yapmasƒ±nƒ± saƒülar.\n<hr>\n\nGenel Ama√ß\n\n.1. **Veri Hazƒ±rlama:** \n    \n.2. **Kayƒ±p Fonksiyonu:** Modelin performansƒ±nƒ± √∂l√ßmek ve iyile≈ütirmek i√ßin kullanƒ±lan bir fonksiyondur.\n    \n.3. **Performans Metriƒüi:** Modelin ne kadar iyi √ßalƒ±≈ütƒ±ƒüƒ±nƒ± deƒüerlendirmek i√ßin kullanƒ±lan metrik.\n    \n.4. **Optimizasyon ve Zamanlama:** Modelin aƒüƒ±rlƒ±klarƒ±nƒ± g√ºncellemek i√ßin kullanƒ±lƒ±r.\n\n","metadata":{}},{"cell_type":"code","source":"# Function to get training and validation data loaders for a given fold\ndef get_data(fold):\n    train_df = df_new[df_new['fold'] != fold].reset_index(drop=True)\n    valid_df = df_new[df_new['fold'] == fold].reset_index(drop=True)\n    \n    train_dataset = LLMTextData(train_df)\n    valid_dataset = LLMTextData(valid_df)\n    \n    train_loader = DataLoader(train_dataset, batch_size=CONFIG.train_batch_size, shuffle=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG.valid_batch_size, shuffle=True)\n    \n    return train_loader, valid_loader\n\n# Loss function definition\ndef loss_fn(outputs, labels):\n    return nn.BCEWithLogitsLoss()(outputs, labels)\n\n# Function to calculate ROC-AUC score\ndef calculate_roc_auc(y_true, y_pred):\n    score = roc_auc_score(y_true, y_pred)\n    return score\n\n# Function to get the optimizer\ndef get_optimizer(model):\n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.weight\"]\n    optimizer_parameters = [\n        {\n            \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n            \"weight_decay\": 0.01\n        },\n        {\n            \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n            \"weight_decay\": 0.0\n        },\n    ]\n\n    optimizer = AdamW(optimizer_parameters, lr=CONFIG.learning_rate)\n\n    return optimizer\n\n# Function to get learning rate scheduler based on the specified type in CONFIG\ndef get_scheduler(cfg, optimizer, train_loader):\n    if cfg.scheduler == 'linear':\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=int((len(train_loader)*CONFIG.epochs*6)/100),\n            num_training_steps=CONFIG.epochs*len(train_loader),\n        )\n    elif cfg.scheduler == 'cosine':\n        scheduler = get_cosine_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=int((len(train_loader)*CONFIG.epochs*6)/100),\n            num_training_steps=CONFIG.epochs*len(train_loader),\n        )\n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2023-12-04T11:49:25.76344Z","iopub.execute_input":"2023-12-04T11:49:25.76385Z","iopub.status.idle":"2023-12-04T11:49:25.778948Z","shell.execute_reply.started":"2023-12-04T11:49:25.763819Z","shell.execute_reply":"2023-12-04T11:49:25.778204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n\n#### A≈üaƒüƒ±daki iki fonksiyon, modelin nasƒ±l eƒüitileceƒüini ve nasƒ±l deƒüerlendirileceƒüini g√∂sterir. (train_fn), modeli ger√ßek etiketlerle eƒüitir. (valid_fn), modelin eƒüitim sƒ±rasƒ±nda nasƒ±l performans g√∂sterdiƒüini deƒüerlendirir.\n\n\n\n","metadata":{}},{"cell_type":"code","source":"# Function to train the model\ndef train_fn(model, data_loader, optimizer, scheduler, device, epoch):\n    # Set the model to training mode\n    model.train()\n    \n    running_loss = 0\n    progress_bar = tqdm(data_loader, position=0)\n    preds = []\n    label = []\n    \n    for step, data in enumerate(progress_bar):\n        # Move data to the specified device\n        ids = data['ids'].to(device)\n        masks = data['mask'].to(device)\n        labels = data['label'].to(device, dtype = torch.float)\n        \n        # Forward pass\n        outputs = model(ids, masks)\n        \n        # Compute the loss\n        loss = loss_fn(outputs, labels.unsqueeze(1))\n        \n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n        # Adjust learning rate if a scheduler is provided\n        if scheduler is not None:\n            scheduler.step()\n        \n        running_loss += loss.item()\n        \n        # Collect predictions and labels for later evaluation\n        preds.extend(torch.sigmoid(outputs).view(-1).cpu().detach().numpy())\n        label.extend(labels.view(-1).cpu().detach().numpy())\n        \n        # Update progress bar\n        progress_bar.set_description(f\"Epoch [{epoch+1}/{CONFIG.epochs}]\")\n        progress_bar.set_postfix(loss=running_loss/(step+1))\n        \n        # Log the loss\n        wandb.log({\"Train Loss\": running_loss/(step+1)})\n    \n    # Calculate ROC-AUC on the training set\n    train_auc = calculate_roc_auc(np.array(label), np.array(preds))\n    \n    return train_auc\n        \n# Function to validate the model        \ndef valid_fn(model, data_loader, device, epoch):\n    # Set the model to evaluation mode\n    model.eval()\n    \n    running_loss = 0\n    progress_bar = tqdm(data_loader, position=0)\n    preds = []\n    label = []\n    \n    with torch.no_grad():\n        \n        for step, data in enumerate(progress_bar):\n            # Move data to the specified device\n            ids = data['ids'].to(device)\n            masks = data['mask'].to(device)\n            labels = data['label'].to(device, dtype = torch.float)\n            \n            # Forward pass\n            outputs = model(ids, masks)\n            \n            # Compute the loss\n            loss = loss_fn(outputs, labels.unsqueeze(1))\n\n            running_loss += loss.item()\n            \n            # Collect predictions and labels for later evaluation\n            preds.extend(torch.sigmoid(outputs).view(-1).cpu().detach().numpy())\n            label.extend(labels.view(-1).cpu().detach().numpy())\n            \n            # Update progress bar\n            progress_bar.set_description(f\"Epoch [{epoch+1}/{CONFIG.epochs}]\")\n            progress_bar.set_postfix(loss=running_loss/(step+1))\n            \n            # Log the loss\n            wandb.log({\"Valid Loss\": running_loss/(step+1)})\n        \n        # Calculate ROC-AUC on the validation set\n        valid_auc = calculate_roc_auc(np.array(label), np.array(preds))\n    \n    return valid_auc         ","metadata":{"execution":{"iopub.status.busy":"2023-12-04T11:49:25.780198Z","iopub.execute_input":"2023-12-04T11:49:25.78048Z","iopub.status.idle":"2023-12-04T11:49:25.797471Z","shell.execute_reply.started":"2023-12-04T11:49:25.780458Z","shell.execute_reply":"2023-12-04T11:49:25.796612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:;\n           padding: 10px 20px\">\n\n* run fonksiyonu, modelin eƒüitim ve doƒürulama s√ºre√ßlerini y√∂netir ve modelin performansƒ±nƒ± deƒüerlendirir.\n    \n    \nModelin veri √ºzerinde ne kadar iyi √∂ƒürendiƒüini anlamak i√ßin ROC-AUC skorlarƒ± kullanƒ±r.\nEƒüitim s√ºresince modelin en iyi performans g√∂sterdiƒüi anƒ±n aƒüƒ±rlƒ±klarƒ± kaydedilir, b√∂ylece model daha sonra bu en iyi durumuyla kullanƒ±labilir.","metadata":{}},{"cell_type":"code","source":"# Function to execute the training and validation process for a specific fold.\ndef run(fold):\n    # Get data loaders for the specified fold\n    train_loader, valid_loader = get_data(fold)\n    \n    # Instantiate the LLMDetectModel and move it to the specified device\n    model = LLMDetectModel(CONFIG.model).to(CONFIG.device)\n    \n    if not os.path.exists(\"./config.pth\"):\n        torch.save(model.config,\"./config.pth\")\n    \n    # Get the optimizer for the model\n    optimizer = get_optimizer(model)\n    \n    # Get the learning rate scheduler based on the specified configuration\n    scheduler = get_scheduler(CONFIG, optimizer, train_loader)\n    \n    # Initialize the best validation ROC-AUC score\n    best_valid_auc = 0\n        \n    # Training loop for the specified number of epochs\n    for epoch in range(CONFIG.epochs):\n        train_auc = train_fn(model, train_loader, optimizer, scheduler, CONFIG.device, epoch)\n        valid_auc = valid_fn(model, valid_loader, CONFIG.device, epoch)\n        print(f\"Train ROC AUC - {train_auc}, Valid ROC AUC - {valid_auc}\")\n        \n        # Log the metrics\n        wandb.log({\"Train AUC\": train_auc})\n        wandb.log({\"Valid AUC\": valid_auc})\n        \n        # Check if the validation ROC-AUC has improved, and if so, save the model checkpoint\n        if valid_auc > best_valid_auc:\n            print(f\"Validation ROC AUC Improved - {best_valid_auc} ---> {valid_auc}\")\n            torch.save(model.state_dict(), f'./model_{fold}.bin')\n            print(f\"Saved model checkpoint at ./model_{fold}.bin\")\n            best_valid_auc = valid_auc\n    \n    return best_valid_auc","metadata":{"execution":{"iopub.status.busy":"2023-12-04T11:52:03.893863Z","iopub.execute_input":"2023-12-04T11:52:03.894201Z","iopub.status.idle":"2023-12-04T11:52:03.903498Z","shell.execute_reply.started":"2023-12-04T11:52:03.894176Z","shell.execute_reply":"2023-12-04T11:52:03.902487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Main loop for training on all folds\nfor fold in range(CONFIG.num_fold):\n    print(\"=\" * 30)\n    print(\"Training Fold - \", fold)\n    print(\"=\" * 30)\n    \n    wandb_run = wandb.init(project='Detect Authors', \n                     group=f\"Fold - {fold}\"\n                     )\n    \n    best_valid_auc = run(fold)\n    print(f'Best ROC AUC: {best_valid_auc:.5f}')\n    \n    wandb_run.finish()\n    \n    gc.collect()\n    torch.cuda.empty_cache()    ","metadata":{"execution":{"iopub.status.busy":"2023-12-04T11:52:53.32311Z","iopub.execute_input":"2023-12-04T11:52:53.32347Z","iopub.status.idle":"2023-12-04T11:53:00.148956Z","shell.execute_reply.started":"2023-12-04T11:52:53.323442Z","shell.execute_reply":"2023-12-04T11:53:00.147596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### [Click here to view the entire dashboard](https://wandb.ai/utcarshagrawal/Detect%20Authors)\n<img src=\"https://i.imgur.com/dTVNOnR.png\">","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n    <h2 align='center'>THANK YOU!!</h2>\n    <h3 align='center'>Please do an upvote if you found the notebook useful.</h3>\n</div>","metadata":{}}]}