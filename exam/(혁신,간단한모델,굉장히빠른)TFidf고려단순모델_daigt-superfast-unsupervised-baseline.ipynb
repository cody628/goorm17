{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"},{"sourceId":7254401,"sourceType":"datasetVersion","datasetId":2820075}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install sparse_dot_topn for fast sparse vector matching\n\nhttps://github.com/ing-bank/sparse_dot_topn","metadata":{}},{"cell_type":"code","source":"!pip install /kaggle/input/sparse-dot-topn-033/sparse_dot_topn-0.3.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:13:32.13321Z","iopub.execute_input":"2024-01-03T06:13:32.13351Z","iopub.status.idle":"2024-01-03T06:14:02.10691Z","shell.execute_reply.started":"2024-01-03T06:13:32.133483Z","shell.execute_reply":"2024-01-03T06:14:02.105371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define TextMatcher","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sparse_dot_topn import awesome_cossim_topn\n\n\nclass TextMatcher:\n    def __init__(self, ground_truth, col, topk=5, lower_bound=-1):\n        self.ground_truth = ground_truth\n        self.vec = TfidfVectorizer(ngram_range=(1, 2), analyzer=\"word\", token_pattern=r\"(?u)(\\b\\w\\w+\\b|[\\.,!])\",\n                                   use_idf=False, min_df=2, binary=True)\n        self.topk = topk\n        self.lower_bound = lower_bound\n        self.col = col\n        \n    def get_matches_df(self, sparse_matrix, texts):\n        non_zeros = sparse_matrix.nonzero()\n\n        text_indices = non_zeros[0]\n        gt_indices = non_zeros[1]\n\n        left_side = np.empty(gt_indices.size, dtype=object)\n        right_side = np.empty(gt_indices.size, dtype=object)\n        match_score = np.zeros(gt_indices.size)\n\n        for index in range(gt_indices.size):\n            left_side[index] = texts.values[text_indices[index]]\n            right_side[index] = self.ground_truth[self.col].values[gt_indices[index]]\n            match_score[index] = sparse_matrix.data[index]\n\n        res_df = pd.DataFrame({self.col: left_side,\n                               'Ground Truth': right_side,\n                               'match_score': match_score})\n\n        res_df = pd.DataFrame(texts).merge(res_df, on=self.col, how=\"left\")\n        return res_df\n\n\n    def match(self, texts_to_match, n_threads=16):\n        print(f\"Matching {texts_to_match.shape[0]} texts to {self.ground_truth.shape[0]} texts...\")\n        \n        X = self.vec.fit_transform(texts_to_match[self.col])\n        X_gt = self.vec.transform(self.ground_truth[self.col])\n        \n        sparse_sim = awesome_cossim_topn(X, X_gt.T, self.topk, self.lower_bound, use_threads=True, n_jobs=n_threads)\n        \n        return self.get_matches_df(sparse_sim, texts_to_match[self.col])","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:29:39.220465Z","iopub.execute_input":"2024-01-03T06:29:39.220818Z","iopub.status.idle":"2024-01-03T06:29:39.233315Z","shell.execute_reply.started":"2024-01-03T06:29:39.22079Z","shell.execute_reply":"2024-01-03T06:29:39.231806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\")\n\nif df.shape[0] == 3: # debug mode\n    df = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\").drop(\"generated\", axis=1)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:29:39.939743Z","iopub.execute_input":"2024-01-03T06:29:39.940145Z","iopub.status.idle":"2024-01-03T06:29:39.990546Z","shell.execute_reply.started":"2024-01-03T06:29:39.940115Z","shell.execute_reply":"2024-01-03T06:29:39.989581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Count keywords in essays\n\nIf both \"because\" and \"thing\" are in an essay, then it is likely that it is written by a student. If none of them are present, then it is likely that it is generated by an LLM.","metadata":{}},{"cell_type":"code","source":"KEYWORDS = [\"because\",\"thing\"]\n\ndef count_keywords(text):\n    count = 0\n    ltext = text.lower()\n    for kw in KEYWORDS:\n        count += (kw in ltext)\n        \n    return count\n\n\ndf[\"keyword_count\"] = df['text'].apply(count_keywords)\ndf[\"likely_student\"] = df[\"keyword_count\"] == 2\ndf[\"likely_llm\"] = df[\"keyword_count\"] == 0\n\ndf[\"keyword_count\"].value_counts() / df.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:29:40.755322Z","iopub.execute_input":"2024-01-03T06:29:40.755867Z","iopub.status.idle":"2024-01-03T06:29:40.776871Z","shell.execute_reply.started":"2024-01-03T06:29:40.755837Z","shell.execute_reply":"2024-01-03T06:29:40.775476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get kth similarity score\n\n30th best match score within likely students and within likely LLMs are calculated.","metadata":{}},{"cell_type":"code","source":"TOPK = 30\n\n\ndef get_match_score(df, gt_filter_col):\n    tm = TextMatcher(df[df[gt_filter_col]].reset_index(drop=True), \"text\", topk=TOPK)\n    res_df = tm.match(df, n_threads=4)\n    df = res_df.groupby(\"text\")[\"match_score\"].min().reset_index().merge(df, on=\"text\")\n    return df\n\nall_prompts = df[\"prompt_id\"].unique()\n\nsub_dfs = [get_match_score(df[df[\"prompt_id\"] == pid], \"likely_student\").reset_index(drop=True)[[\"id\", \"match_score\"]]\n           for pid in all_prompts]\nsub_df = pd.concat(sub_dfs).rename(columns={\"match_score\": \"match_score_student\"})\n\n\nsub_dfs = [get_match_score(df[df[\"prompt_id\"] == pid], \"likely_llm\").reset_index(drop=True)[[\"id\", \"match_score\"]]\n           for pid in all_prompts]\nsub_df2 = pd.concat(sub_dfs).rename(columns={\"match_score\": \"match_score_llm\"})\n\nsub_df = sub_df.merge(sub_df2, on=\"id\")\nsub_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:29:41.954858Z","iopub.execute_input":"2024-01-03T06:29:41.955236Z","iopub.status.idle":"2024-01-03T06:29:46.494045Z","shell.execute_reply.started":"2024-01-03T06:29:41.955204Z","shell.execute_reply":"2024-01-03T06:29:46.492503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make submission\n\nRatio between student match score and smoothed LLM match score determines the ranking of essays.","metadata":{}},{"cell_type":"code","source":"SMOOTH = 0.15\n\nsub_df[\"generated\"] = -sub_df[\"match_score_student\"] / (sub_df[\"match_score_llm\"] + SMOOTH)\n\nsub_df.to_csv(\"submission.csv\", index=False, columns=[\"id\", \"generated\"])","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:29:46.49609Z","iopub.execute_input":"2024-01-03T06:29:46.496455Z","iopub.status.idle":"2024-01-03T06:29:46.509945Z","shell.execute_reply.started":"2024-01-03T06:29:46.496422Z","shell.execute_reply":"2024-01-03T06:29:46.508628Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
